{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MapReduce-NaiveBayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vfwiBpW6V4z"
      },
      "source": [
        "### **Implementing Naive Bayes in pure Python using a MapReduce Approach**\r\n",
        "Consider implementing a simple counting function where we sum the double of a range of numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xO0u_k961Zv"
      },
      "source": [
        "numbers = list(range(1000))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rovBazc_VxD",
        "outputId": "c479fc2a-113b-41cc-d6aa-9a0f904c3013"
      },
      "source": [
        "print (numbers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS7PATOy0xSm",
        "outputId": "8466efdb-3894-4caa-f50b-5616dbc9deac"
      },
      "source": [
        "type(numbers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLr0V7gF_R52"
      },
      "source": [
        "def doubled_sum(values):\r\n",
        "    total = 0\r\n",
        "    for n in numbers:\r\n",
        "        total += n*2\r\n",
        "    return total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwvgQTps7GOx"
      },
      "source": [
        "We can print the outcome using\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QUpzAVy7RCi",
        "outputId": "5af9c14f-b0a4-4b55-eed1-e0a7464fa75b"
      },
      "source": [
        "print(doubled_sum(numbers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "999000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCxXP0197yM1"
      },
      "source": [
        "**MapReduce version of Example Problem**\r\n",
        "\r\n",
        "As Python implements the functional programming paradigm too, it provides the functions required to implement the map-reduce paradigm builtin.\r\n",
        "\r\n",
        "The foundation tools to implement map reduce are:\r\n",
        "\r\n",
        "1.   \"mapper\" which is in charge of mapping each input value to a corresponding output value\r\n",
        "2.   \"reducer\" which is in charge of merging multiple mapper outputs into a single output.\r\n",
        "\r\n",
        "  \r\n",
        "Both phases can be called multiple times (the output of a reducer can become the input of another reducer and a mapper can call other mappers).\r\n",
        "\r\n",
        "Many MapReduce implementations also have additional phases like \"combination\" and \"aggregation\" which are executed after the mapper or the reducer to further modify their output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-cEQsqn8JlC"
      },
      "source": [
        "numbers = list(range(1000))\r\n",
        "\r\n",
        "def mapper(value):\r\n",
        "    return value*2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWhe0LjW2HCA"
      },
      "source": [
        "print(mapper(numbers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuTbqB2l2mMK"
      },
      "source": [
        "def reducer(*values):\r\n",
        "    return sum(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvnFX68J8evd"
      },
      "source": [
        "#We can output the result of applying the map function as follows\r\n",
        "first_step = map(mapper, numbers)\r\n",
        "print (first_step)\r\n",
        "\r\n",
        "#Next we can generate the output from the reducer and print it\r\n",
        "result = reduce(reducer, map(mapper, numbers))\r\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJldU_-58Q2S"
      },
      "source": [
        "\r\n",
        "\r\n",
        "The previous map-reduce in pure python implementation lacks of course the core feature of MapReduce: working parallely.\r\n",
        "\r\n",
        "It's easy to understand that as each mapper and reducer works only on a subset of the data (its own input) it can work independently from the status of the other mappers and reducers. So the computation can proceed parallely.\r\n",
        "Parallel Map Reduce in Pure Python\r\n",
        "\r\n",
        "It's really easy to simulate a parallel map reduce in python by using the multiprocessing module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv7nGuSCEYGU"
      },
      "source": [
        "import numpy as np  # Make numpy available using np.\r\n",
        "from itertools import islice\r\n",
        "import multiprocessing\r\n",
        "\r\n",
        "\r\n",
        "class ParallelMapReduce(object):\r\n",
        "    def __init__(self, map_func, reduce_func, num_workers=None):\r\n",
        "        self.num_workers = num_workers\r\n",
        "        self.map_func = map_func\r\n",
        "        self.reduce_func = reduce_func\r\n",
        "        self.pool = multiprocessing.Pool(num_workers)\r\n",
        "    \r\n",
        "    def partition(self, n, iterable):\r\n",
        "        i = iter(iterable)\r\n",
        "        piece = list(islice(i, n))\r\n",
        "        while piece:\r\n",
        "            yield piece\r\n",
        "            piece = list(islice(i, n))\r\n",
        "    \r\n",
        "    def __call__(self, inputs):\r\n",
        "        values = self.pool.map(self.map_func, inputs)\r\n",
        "        \r\n",
        "        print '>>> MAPPED VALUES (%s values): %s, ...' % (len(values), str(values[:10]))\r\n",
        "\r\n",
        "        values = self.pool.map(self.reduce_func, \r\n",
        "                               self.partition(len(values)//self.num_workers, values))\r\n",
        "        print '>>> REDUCED VALUES', values\r\n",
        "\r\n",
        "        return self.reduce_func(values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eH3P-8IEi6-"
      },
      "source": [
        "The previous mapreduce implementation takes a Mapper and a Reducer and splits them across num_workers until it gets back the final result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN7YvHV_Em2b"
      },
      "source": [
        "numbers = range(1000)\r\n",
        "\r\n",
        "def mapper(value):\r\n",
        "    return value*2\r\n",
        "\r\n",
        "def reducer(values):\r\n",
        "    return sum(values)\r\n",
        "\r\n",
        "mapreduce = ParallelMapReduce(mapper, reducer, 10)\r\n",
        "print mapreduce(numbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cKc6yDWcnEh"
      },
      "source": [
        "Use the previous code fragments to do the following: \r\n",
        "\r\n",
        "1.   Implement a purely sequential version of Naive Bayes for Mapreduce\r\n",
        "2.   Implement a ParallelMapReduce version of Naive Bayes.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3CLBgjAWGA8"
      },
      "source": [
        "In this project we will apply Naive Bayes to the well-known data set of mushroom data. This is found at\r\n",
        "\r\n",
        "https://archive.ics.uci.edu/ml/datasets/mushroom\r\n",
        "\r\n",
        "The zip-file of the data is given as part of the assignment.\r\n",
        "\r\n",
        "Data Set Information:\r\n",
        "\r\n",
        "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.\r\n",
        "\r\n",
        "The dataset consists of 8124 training examples, each representing a single mushroom. The first column is the target variable containing the class labels, identifying whether the mushroom is poisonous or edible. The remaining columns are 22 discrete features that describe the mushroom in some observable way; their values are encoded by characters. For example, gill size is either broad (b) or narrow (n), and veil color can be brown (n), orange (o), white (w), or yellow (y). Each feature has numerous values, as described below.\r\n",
        "\r\n",
        "Attribute Information:\r\n",
        "\r\n",
        "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\r\n",
        "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\r\n",
        "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\r\n",
        "4. bruises?: bruises=t,no=f\r\n",
        "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\r\n",
        "6. gill-attachment: attached=a,descending=d,free=f,notched=n\r\n",
        "7. gill-spacing: close=c,crowded=w,distant=d\r\n",
        "8. gill-size: broad=b,narrow=n\r\n",
        "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\r\n",
        "10. stalk-shape: enlarging=e,tapering=t\r\n",
        "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\r\n",
        "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\r\n",
        "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\r\n",
        "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\r\n",
        "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\r\n",
        "16. veil-type: partial=p,universal=u\r\n",
        "17. veil-color: brown=n,orange=o,white=w,yellow=y\r\n",
        "18. ring-number: none=n,one=o,two=t\r\n",
        "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\r\n",
        "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\r\n",
        "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\r\n",
        "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\r\n",
        "\r\n",
        "\r\n",
        "The data description indicates that the feature stalk root has some missing values, denoted by ?. In this analysis, we'll read in the data and then exclude any training example that has missing values for stalk root.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WG68Jy1ZEGw"
      },
      "source": [
        "# Mushroom Data Set\r\n",
        "# https://archive.ics.uci.edu/ml/datasets/Mushroom\r\n",
        "# Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml].\r\n",
        "# Irvine, CA: University of California, School of Information and Computer Science.\r\n",
        "\r\n",
        "#We have provided a zip file with the data, but you can load it from the web if you want\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "data = pd.read_table('data/agaricus-lepiota.data', delimiter=',', header=None)\r\n",
        "#exclude any training example that has missing values for stalk root\r\n",
        "data = data[data['stalk root'] != '?']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuykI29mh2yP"
      },
      "source": [
        "You will need to train your classifier, and then evaluate the predictive accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohdGTLdhFDQi"
      },
      "source": [
        "\r\n",
        "#first we must do a bit of data inspection and cleaning\r\n",
        "y = data[:,0]\r\n",
        "X = data[:,1:]\r\n",
        "\r\n",
        "\r\n",
        "Cn=len(np.unique(y))\r\n",
        "\r\n",
        "n,d = X.shape\r\n",
        "\r\n",
        "print (\"initial samples: {}\".format(n))\r\n",
        "print (\"number of features: {}\".format(d))\r\n",
        "print (\"number of class labels: {}\".format(Cn))\r\n",
        "print ()\r\n",
        "\r\n",
        "print (\"Class Labels are: {}\".format(np.unique(y)))\r\n",
        "print ()\r\n",
        "\r\n",
        "print (\"Take a look at unique outcomes per feature\")\r\n",
        "for i in range(0,d):\r\n",
        "\tprint (\"{}th: {}\".format(i,np.unique(X[:,i])))\r\n",
        "\r\n",
        "X = np.delete(X,(10,15),axis=1)\r\n",
        "\r\n",
        "print ()\r\n",
        "print (\"Remove 10th feature because it has some missing data\")\r\n",
        "print (\"Remove 15th feature because it is always 'p'\")\r\n",
        "\r\n",
        "#You do not need to use the following code, if you want\r\n",
        "\r\n",
        "n,d = X.shape\r\n",
        "\r\n",
        "# dictionary master list of unique features\r\n",
        "featureDict = {}\r\n",
        "for i in range(0,d):\r\n",
        "\tfeatureDict[i]= np.unique(X[:,i])\r\n",
        "\r\n",
        "print ()\r\n",
        "print (\"After removing the two features\")\r\n",
        "print (\"number of features: {}\".format(d))\r\n",
        "\r\n",
        "# split data into training and test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\r\n",
        "n_train = len(X_train)\r\n",
        "n_test = len(X_test)\r\n",
        "\r\n",
        "print ()\r\n",
        "print (\"number of training samples: {}\".format(n_train))\r\n",
        "print (\"number of test samples: {}\".format(n_test))\r\n",
        "\r\n",
        "# Isolate the training set based on clasification label\r\n",
        "X_train_e = X_train[y_train=='e']\r\n",
        "X_train_p = X_train[y_train=='p']\r\n",
        "\r\n",
        "# capture number of each class label in training set\r\n",
        "n_train_e = len(X_train_e)\r\n",
        "n_train_p = len(X_train_p)\r\n",
        "\r\n",
        "# two dictionaries to capture likelihoods (features given class labels)\r\n",
        "featureGivenEd = {}\r\n",
        "featureGivenPo = {}\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTJPCJUbiFsW"
      },
      "source": [
        "# some helper code that may be useful for performance evaluation on the test set\r\n",
        "print ()\r\n",
        "print (\"Probability of correct prediction\")\r\n",
        "print ((y_test_pred==y_test).sum()/n_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}